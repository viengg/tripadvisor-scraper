{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0ce1e901da04acbe50dd99cd0d91cb411cb2166c3507dec81ce620981a8df4741",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ce1e901da04acbe50dd99cd0d91cb411cb2166c3507dec81ce620981a8df4741"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "#from wordcloud import WordCloud\n",
    "import os\n",
    "import emoji\n",
    "from collections import Counter\n",
    "from sentistrength import PySentiStr\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11, 4)})\n",
    "plt.rcParams['figure.figsize']  = (18, 10)\n",
    "plt.rcParams['axes.labelsize']  = 20\n",
    "plt.rcParams['axes.titlesize']  = 20\n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['lines.linewidth'] = 4\n",
    "plt.ion()\n",
    "plt.style.use('seaborn-colorblind')\n",
    "plt.rcParams['figure.figsize']  = (12, 8) # não sei o motivo, mas o use acima reseta o size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_indef(dataframe, coluna):\n",
    "    return dataframe[(dataframe[coluna] != 'indef') & (dataframe[coluna] != None)]\n",
    "\n",
    "def convert_to_datetime(dataframe, coluna_data):\n",
    "    return pd.to_datetime(dataframe[coluna_data])\n",
    "\n",
    "def filter_reviews_by_year(dataframe, ano, coluna_data='data_avaliacao'):\n",
    "    df_without_indef = drop_indef(dataframe, coluna_data)\n",
    "    df_without_indef[coluna_data] = convert_to_datetime(df_without_indef, coluna_data)\n",
    "    expressao = coluna_data+'.dt.year >= ' + str(ano)\n",
    "    return df_without_indef.query(expressao)\n",
    "\n",
    "def normalize(df):\n",
    "    return (df-df.mean())/df.std()\n",
    "\n",
    "def removerAcentosECaracteresEspeciais(frase):\n",
    "    \n",
    "    frase_sem_acento = unidecode(frase) #remove acentos\n",
    "    # Usa expressão regular para retornar a palavra apenas com números, letras e espaço\n",
    "    return re.sub('[^a-zA-Z0-9 \\\\\\]', '', frase_sem_acento)\n",
    "\n",
    "def tokenize_frase(frase):\n",
    "    token_pontuacao = nltk.tokenize.WordPunctTokenizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    #frase_sem_acento = removerAcentosECaracteresEspeciais(frase).lower()\n",
    "    frase_splitted = token_pontuacao.tokenize(frase.lower())\n",
    "    nova_frase = ' '.join(filter(lambda palavra: palavra not in stopwords, frase_splitted))\n",
    "\n",
    "    return ' '.join(removerAcentosECaracteresEspeciais(nova_frase).split())\n",
    "\n",
    "def wordcloud(dataframe, titulo, cidade, coluna_texto=''):\n",
    "    titulo = titulo + ' em ' + cidade\n",
    "    if coluna_texto == '':\n",
    "        todas_palavras = ' '.join(dataframe)\n",
    "    else:\n",
    "        todas_palavras = ' '.join([texto for texto in dataframe[coluna_texto]]) #lista contendo todas as frases\n",
    "\n",
    "    word_cloud = WordCloud(width=1200, \n",
    "                            height=800, \n",
    "                            max_font_size=110, \n",
    "                            background_color='gray',\n",
    "                            max_words=50,\n",
    "                            colormap='gist_rainbow').generate(todas_palavras)\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.title(titulo)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    title = 'wordcloud_'+titulo.replace(' ','_').lower()\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "    plt.show()\n",
    "\n",
    "def carrega_cidades(cidade):\n",
    "    hotel = pd.read_csv(os.path.join(cidade, 'hoteis.csv'), float_precision=None).drop_duplicates('hotel_id')\n",
    "    restaurantes = pd.read_csv(os.path.join(cidade, 'restaurantes.csv'), float_precision=None).drop_duplicates()\n",
    "    atracoes = pd.read_csv(os.path.join(cidade, 'atracoes.csv'), float_precision=None).drop_duplicates()\n",
    "\n",
    "    aval_hotel = pd.read_csv(os.path.join(cidade, 'avaliacoes-hoteis.csv')).drop_duplicates()\n",
    "    aval_rest = pd.read_csv(os.path.join(cidade, 'avaliacoes-restaurantes.csv'))\n",
    "    aval_rest = aval_rest.drop_duplicates(aval_rest.columns[:-2])\n",
    "    aval_atracoes = pd.read_csv(os.path.join(cidade, 'avaliacoes-atracoes.csv')).drop_duplicates()\n",
    "\n",
    "\n",
    "    data = {'estabelecimentos': {'hoteis': hotel, 'restaurantes': restaurantes, 'atracoes': atracoes},\n",
    "            'avaliacoes': {'aval_hotel': aval_hotel, 'aval_rest': aval_rest, 'aval_atracoes': aval_atracoes}}\n",
    "    return data\n",
    "\n",
    "def inicializa_diretorios_graficos(cidade):\n",
    "    if not os.path.exists('graficos'):\n",
    "        os.mkdir('graficos')\n",
    "\n",
    "    if not os.path.exists(os.path.join('graficos', cidade)):\n",
    "        os.mkdir(os.path.join('graficos', cidade))\n",
    "\n",
    "def descreve_cidades(cidade):\n",
    "    inicializa_diretorios_graficos(cidade)\n",
    "    dados_cidade = carrega_cidades(cidade)\n",
    "    estabelecimentos = dados_cidade['estabelecimentos']\n",
    "    avaliacoes = dados_cidade['avaliacoes']\n",
    "    avaliacoes_recentes = filtra_avaliacoes_antigas(avaliacoes)\n",
    "    avaliacoes_pandemia = filtra_avaliacoes_antigas(avaliacoes, ano=2019)\n",
    "\n",
    "    # distribuicao_hoteis(estabelecimentos['hoteis'], cidade)\n",
    "    # distribuicao_preco_restaurantes(estabelecimentos['restaurantes'], cidade)\n",
    "\n",
    "    # reviews_por_mes(cidade, avaliacoes_recentes)\n",
    "    # reviews_por_ano(cidade, avaliacoes_recentes)\n",
    "\n",
    "    # compara_aval_hotel_por_tipo(cidade, estabelecimentos['hoteis'], avaliacoes_recentes['aval_hotel'])\n",
    "    # compara_aval_rest_por_tipo(cidade, estabelecimentos['restaurantes'], avaliacoes_recentes['aval_rest'])\n",
    "\n",
    "    # aval_durante_pandemia(cidade, avaliacoes_pandemia)\n",
    "\n",
    "    # tam_aval(cidade, avaliacoes_pandemia, 'characters')\n",
    "    # tam_aval(cidade, avaliacoes_pandemia, 'words')\n",
    "\n",
    "    # porcentagem_comentarios_com_emoji(cidade, avaliacoes_pandemia)\n",
    "    distribuicao_emojis(cidade, avaliacoes_pandemia, 2020)\n",
    "\n",
    "def wordclouds(cidade):\n",
    "    dados_cidade = carrega_cidades(cidade)\n",
    "    avaliacoes = dados_cidade['avaliacoes']\n",
    "    avaliacoes_pandemia = filtra_avaliacoes_antigas(avaliacoes, ano=2019)\n",
    "    avaliacoes_processadas = pre_processa_aval(avaliacoes_pandemia)\n",
    "    word_clouds_por_cidade(cidade, avaliacoes_processadas)\n",
    "\n",
    "\n",
    "def distribuicao_hoteis(hoteis, cidade):\n",
    "    tipos_hoteis = hoteis.groupby('tipo')['nome'].count().rename({'Chale': 'Cottage', 'Hostel': 'Hostel', 'Hotel':'Hotel', 'Pousada': 'Lodge', 'indef':'indef'})\n",
    "    tipos_hoteis.plot.bar()\n",
    "    plt.xlabel('Hotel Type')\n",
    "    plt.ylabel('Number of entires')\n",
    "    plt.title('Distribution of hotel types in ' + cidade)\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' hotel distribution').replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def distribuicao_preco_restaurantes(restaurantes, cidade):\n",
    "    restaurantes.groupby('categoria_preco')['nome'].count().rename({'$$$$': '\\\\$\\\\$\\\\$\\\\$'}).plot.bar()\n",
    "    plt.xlabel('Price category')\n",
    "    plt.ylabel('Number of entires')\n",
    "    plt.title('Distribution of restaurants price categories in ' + cidade)\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' restaurant price category distribution').replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def filtra_avaliacoes_antigas(avaliacoes, ano=2015):\n",
    "    aval_hotel_recente = filter_reviews_by_year(avaliacoes['aval_hotel'], ano)\n",
    "    aval_rest_recente = filter_reviews_by_year(avaliacoes['aval_rest'], ano)\n",
    "    aval_atracoes_recente = filter_reviews_by_year(avaliacoes['aval_atracoes'], ano)\n",
    "\n",
    "    data = {'aval_hotel': aval_hotel_recente, 'aval_rest': aval_rest_recente, 'aval_atracoes': aval_atracoes_recente}\n",
    "    return data\n",
    "\n",
    "def reviews_por_mes(cidade, avaliacoes):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, figsize=(16, 24))\n",
    "\n",
    "    avaliacoes['aval_hotel'].set_index('data_avaliacao')['estabelecimento'].resample('M').count().plot(ax=ax1)\n",
    "    ax1.set(xlabel='Date', ylabel='Number of reviews')\n",
    "    ax1.set_title(\"Hotel reviews by month in \" + cidade)\n",
    "    avaliacoes['aval_rest'].set_index('data_avaliacao')['estabelecimento'].resample('M').count().plot(ax=ax2)\n",
    "    ax2.set(xlabel='Date', ylabel='Number of reviews')\n",
    "    ax2.set_title(\"Restaurant reviews by month in \" + cidade)\n",
    "    avaliacoes['aval_atracoes'].set_index('data_avaliacao')['estabelecimento'].resample('M').count().plot(ax=ax3)\n",
    "    ax3.set(xlabel='Date', ylabel='Number of reviews')\n",
    "    ax3.set_title(\"Attraction reviews by month in \" + cidade)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' reviews by month').replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def reviews_por_ano(cidade, avaliacoes):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, figsize=(16, 24))\n",
    "\n",
    "    avaliacoes['aval_hotel'].groupby(avaliacoes['aval_hotel']['data_avaliacao'].dt.year)['estabelecimento'].count().plot(ax=ax1, kind='bar')\n",
    "    ax1.set(xlabel='Year', ylabel='Number of reviews')\n",
    "    ax1.set_title(\"Hotel reviews by year in \" + cidade)\n",
    "    avaliacoes['aval_rest'].groupby(avaliacoes['aval_rest']['data_avaliacao'].dt.year)['estabelecimento'].count().plot(ax=ax2, kind='bar')\n",
    "    ax2.set(xlabel='Year', ylabel='Number of reviews')\n",
    "    ax2.set_title(\"Restaurant reviews by year in \" + cidade)\n",
    "    avaliacoes['aval_atracoes'].groupby(avaliacoes['aval_atracoes']['data_avaliacao'].dt.year)['estabelecimento'].count().plot(ax=ax3, kind='bar')\n",
    "    ax3.set(xlabel='Year', ylabel='Number of reviews')\n",
    "    ax3.set_title(\"Attraction reviews by year in \" + cidade)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' reviews by year').replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def compara_aval_hotel_por_tipo(cidade, hoteis, aval_hotel):\n",
    "    merged_df = pd.merge(hoteis, aval_hotel, how='right', left_on='hotel_id', right_on='estabelecimento_id')\n",
    "\n",
    "    avaliacoes_tipo_hotel = merged_df[merged_df['tipo'] == 'Hotel']\n",
    "    avaliacoes_tipo_pousada = merged_df[merged_df['tipo'] == 'Pousada']\n",
    "\n",
    "    plt.figure(figsize=(18,10))\n",
    "    plt.plot(normalize(avaliacoes_tipo_hotel.set_index('data_avaliacao')['estabelecimento'].resample('M').count()))\n",
    "    plt.plot(normalize(avaliacoes_tipo_pousada.set_index('data_avaliacao')['estabelecimento'].resample('M').count()))\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of reviews')\n",
    "    plt.title('Hotel reviews by type (normalized) in ' + cidade)\n",
    "    plt.legend(['Hotel', 'Lodge'])\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' reviews by hotel type').replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def compara_aval_rest_por_tipo(cidade, restaurantes, aval_rest):\n",
    "    merged_df = pd.merge(restaurantes, aval_rest, how='right', left_on='restaurante_id', right_on='estabelecimento_id')\n",
    "\n",
    "    avaliacoes_rest_barato = merged_df[merged_df['categoria_preco'] == '$']\n",
    "    avaliacoes_rest_med = merged_df[merged_df['categoria_preco'] == '$$ - $$$']\n",
    "\n",
    "    plt.figure(figsize=(18,10))\n",
    "    plt.plot(normalize(avaliacoes_rest_barato.set_index('data_avaliacao')['estabelecimento'].resample('M').count()))\n",
    "    plt.plot(normalize(avaliacoes_rest_med.set_index('data_avaliacao')['estabelecimento'].resample('M').count()))\n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of reviews')\n",
    "    plt.title('Restaurant reviews by price category in ' + cidade)\n",
    "    plt.legend(['$', '$$ - $$$'])\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' reviews by restaurant category').replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def aval_durante_pandemia(cidade, avaliacoes):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, figsize=(16, 24))\n",
    "\n",
    "    avaliacoes['aval_hotel'].set_index('data_avaliacao')['estabelecimento'].resample('M').count().plot(ax=ax1, style='-', marker='o', markerfacecolor='black', markersize=8)\n",
    "    ax1.set(xlabel='Date', ylabel='Number of reviews')\n",
    "    ax1.set_title(\"Hotel reviews by month in \" + cidade)\n",
    "    avaliacoes['aval_rest'].set_index('data_avaliacao')['estabelecimento'].resample('M').count().plot(ax=ax2, style='-', marker='o', markerfacecolor='black', markersize=8)\n",
    "    ax2.set(xlabel='Date', ylabel='Number of reviews')\n",
    "    ax2.set_title(\"Restaurant reviews by month in \" + cidade)\n",
    "    avaliacoes['aval_atracoes'].set_index('data_avaliacao')['estabelecimento'].resample('M').count().plot(ax=ax3, style='-', marker='o', markerfacecolor='black', markersize=8)\n",
    "    ax3.set(xlabel='Date', ylabel='Number of reviews')\n",
    "    ax3.set_title(\"Attraction reviews by month in \" + cidade)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' reviews by month pandemic').replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def tam_aval(cidade, avaliacoes, mode):\n",
    "    if mode =='characters':\n",
    "        size_column = 'tam_chars'\n",
    "        avaliacoes['aval_hotel'][size_column] = avaliacoes['aval_hotel'].apply(lambda row: len(row['conteudo']), axis=1)\n",
    "        avaliacoes['aval_rest'][size_column] = avaliacoes['aval_rest'].apply(lambda row: len(row['conteudo']), axis=1)\n",
    "        avaliacoes['aval_atracoes'][size_column] = avaliacoes['aval_atracoes'].apply(lambda row: len(row['conteudo']), axis=1)\n",
    "    elif mode == 'words':\n",
    "        size_column = 'tam_words'\n",
    "        avaliacoes['aval_hotel'][size_column] = avaliacoes['aval_hotel'].apply(lambda row: len(row['conteudo'].split()), axis=1)\n",
    "        avaliacoes['aval_rest'][size_column] = avaliacoes['aval_rest'].apply(lambda row: len(row['conteudo'].split()), axis=1)\n",
    "        avaliacoes['aval_atracoes'][size_column] = avaliacoes['aval_atracoes'].apply(lambda row: len(row['conteudo'].split()), axis=1)\n",
    "    else:\n",
    "        print('Modo incorreto (characters/words)!')\n",
    "        return\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, figsize=(16, 24))\n",
    "\n",
    "    avaliacoes['aval_hotel'].set_index('data_avaliacao')[size_column].resample('M').mean().fillna(0).plot(ax=ax1, style='-', marker='o', markerfacecolor='black', markersize=8)\n",
    "    ax1.set(xlabel='Date', ylabel='Average review length')\n",
    "    ax1.set_title('Hotel review length in ' + cidade + ' by ' + mode)\n",
    "    avaliacoes['aval_rest'].set_index('data_avaliacao')[size_column].resample('M').mean().fillna(0).plot(ax=ax2, style='-', marker='o', markerfacecolor='black', markersize=8)\n",
    "    ax2.set(xlabel='Date', ylabel='Average review length')\n",
    "    ax2.set_title('Restaurant review length in ' + cidade + ' by ' + mode)\n",
    "    avaliacoes['aval_atracoes'].set_index('data_avaliacao')[size_column].resample('M').mean().fillna(0).plot(ax=ax3, style='-', marker='o', markerfacecolor='black', markersize=8)\n",
    "    ax3.set(xlabel='Date', ylabel='Average review length')\n",
    "    ax3.set_title('Attraction review length in ' + cidade + ' by ' + mode)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' review length ' + mode).replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def pre_processa_aval(avaliacoes):\n",
    "    aval_hotel_pt = avaliacoes['aval_hotel'].query('idioma == \"pt\"')\n",
    "    aval_rest_pt = avaliacoes['aval_rest'].query('idioma == \"pt\"')\n",
    "    aval_atr_pt = avaliacoes['aval_atracoes'].query('idioma == \"pt\"')\n",
    "\n",
    "    aval_hotel_pt['processado'] = aval_hotel_pt.apply(lambda row: tokenize_frase(row['conteudo']), axis=1)\n",
    "    aval_rest_pt['processado'] = aval_rest_pt.apply(lambda row: tokenize_frase(row['conteudo']), axis=1)\n",
    "    aval_atr_pt['processado'] = aval_atr_pt.apply(lambda row: tokenize_frase(row['conteudo']), axis=1)\n",
    "\n",
    "    return {'aval_hotel': aval_hotel_pt, 'aval_rest': aval_rest_pt, 'aval_atracoes': aval_atr_pt}\n",
    "\n",
    "def desenha_wordclouds(avaliacoes, modo, cidade):\n",
    "    wordcloud(avaliacoes.query('data_avaliacao.dt.year == 2019 and data_avaliacao.dt.month <= 6'), modo.capitalize() + ' - Primeiro semestre 2019', cidade, 'processado')\n",
    "    wordcloud(avaliacoes.query('data_avaliacao.dt.year == 2019 and data_avaliacao.dt.month > 6'), modo.capitalize() + ' - Segundo semestre 2019', cidade, 'processado')\n",
    "    wordcloud(avaliacoes.query('data_avaliacao.dt.year == 2020 and data_avaliacao.dt.month <= 6'), modo.capitalize() + ' - Primeiro semestre 2020', cidade, 'processado')\n",
    "    wordcloud(avaliacoes.query('data_avaliacao.dt.year == 2020 and data_avaliacao.dt.month > 6'), modo.capitalize() + '- Segundo semestre 2020', cidade, 'processado')\n",
    "    wordcloud(avaliacoes.query('data_avaliacao.dt.year >= 2021'), modo.capitalize() + ' - 2021', cidade, 'processado')\n",
    "\n",
    "def word_clouds_por_cidade(cidade, avaliacoes):\n",
    "    todos_comentarios = avaliacoes['aval_hotel'][['processado', 'data_avaliacao']].append([avaliacoes['aval_rest'][['processado', 'data_avaliacao']], avaliacoes['aval_atracoes'][['processado', 'data_avaliacao']]], ignore_index=True)\n",
    "\n",
    "    desenha_wordclouds(todos_comentarios, 'agregado', cidade)\n",
    "    desenha_wordclouds(avaliacoes['aval_hotel'], 'hotéis', cidade)\n",
    "    desenha_wordclouds(avaliacoes['aval_rest'], 'restaurantes', cidade)\n",
    "    desenha_wordclouds(avaliacoes['aval_atracoes'], 'atrações', cidade)\n",
    "\n",
    "def is_emoji(char):\n",
    "    for key in emoji.UNICODE_EMOJI:\n",
    "        if char in emoji.UNICODE_EMOJI[key]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def has_emoji(string):\n",
    "    for char in string:\n",
    "        if is_emoji(char):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def porcentagem_comentarios_com_emoji(cidade, avaliacoes):\n",
    "    avaliacoes['aval_hotel']['tem_emoji'] =  avaliacoes['aval_hotel'].apply(lambda row: has_emoji(row['conteudo']), axis=1)\n",
    "    avaliacoes['aval_rest']['tem_emoji'] =  avaliacoes['aval_rest'].apply(lambda row: has_emoji(row['conteudo']), axis=1)\n",
    "    avaliacoes['aval_atracoes']['tem_emoji'] =  avaliacoes['aval_atracoes'].apply(lambda row: has_emoji(row['conteudo']), axis=1)\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, figsize=(16, 24))\n",
    "    (avaliacoes['aval_hotel'].groupby('tem_emoji')['conteudo'].count()/len(avaliacoes['aval_hotel'])).plot.bar(ax=ax1, rot=0)\n",
    "    ax1.set(xlabel='Has emoji?', ylabel='Proportion')\n",
    "    ax1.set_title('Proportion of hotel reviews that have emojis in ' + cidade)\n",
    "    (avaliacoes['aval_rest'].groupby('tem_emoji')['conteudo'].count()/len(avaliacoes['aval_rest'])).plot.bar(ax=ax2, rot=0)\n",
    "    ax2.set(xlabel='Has emoji?', ylabel='Proportion')\n",
    "    ax2.set_title('Proportion of restaurant reviews that have emojis in ' + cidade)\n",
    "    (avaliacoes['aval_atracoes'].groupby('tem_emoji')['conteudo'].count()/len(avaliacoes['aval_atracoes'])).plot.bar(ax=ax3, rot=0)\n",
    "    ax3.set(xlabel='Has emoji?', ylabel='Proportion')\n",
    "    ax3.set_title('Proportion of attraction reviews that have emojis in ' + cidade)\n",
    "\n",
    "    for ax in (ax1, ax2, ax3):\n",
    "        for p in ax.patches:\n",
    "            width = p.get_width()\n",
    "            height = p.get_height()\n",
    "            x, y = p.get_xy() \n",
    "            ax.annotate(f'{height:.0%}', (x + width/2, y + height*1.02), ha='center', size='large')\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' emoji presence distribution').replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def distribuicao_emojis(cidade, avaliacoes, ano):\n",
    "    todas_palavras_hoteis = ' '.join([texto for texto in avaliacoes['aval_hotel'].query(f\"data_avaliacao.dt.year == {ano}\")['conteudo']])\n",
    "    todas_palavras_rest = ' '.join([texto for texto in avaliacoes['aval_rest'].query(f\"data_avaliacao.dt.year == {ano}\")['conteudo']])\n",
    "    todas_palavras_atr = ' '.join([texto for texto in avaliacoes['aval_atracoes'].query(f\"data_avaliacao.dt.year == {ano}\")['conteudo']])\n",
    "\n",
    "    todos_comentarios = todas_palavras_hoteis + ' ' + todas_palavras_rest + ' ' + todas_palavras_atr\n",
    "\n",
    "    emojis = list(filter(is_emoji, todos_comentarios))\n",
    "    c = Counter(emojis)\n",
    "    df = pd.DataFrame.from_records(c.most_common(10), columns=['emoji','count'])\n",
    "    print(df)\n",
    "\n",
    "    df.plot.bar(legend=False, rot=0)\n",
    "    plt.xlabel('Emojis')\n",
    "    plt.ylabel('Occurrences')\n",
    "    plt.title('Emoji distribution in ' + cidade)\n",
    "    plt.tight_layout()\n",
    "    title = (cidade.lower()+' emoji distribution').replace(' ','_')\n",
    "    #plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def analise_sentimento(cidade, aval_processadas, senti, tipo_aval):\n",
    "\n",
    "    aval_processadas['sentimento'] = aval_processadas.apply(lambda row: senti.getSentiment(row['processado'])[0], axis=1)\n",
    "\n",
    "    primeiro_semestre_2019 = separa_avaliacoes_por_semestre(aval_processadas, 2019, 1).groupby('sentimento')['sentimento'].count()\n",
    "    segundo_semestre_2019 = separa_avaliacoes_por_semestre(aval_processadas, 2019, 2).groupby('sentimento')['sentimento'].count()\n",
    "    primeiro_semestre_2020 = separa_avaliacoes_por_semestre(aval_processadas, 2020, 1).groupby('sentimento')['sentimento'].count()\n",
    "    segundo_semestre_2020 = separa_avaliacoes_por_semestre(aval_processadas, 2020, 2).groupby('sentimento')['sentimento'].count()\n",
    "    primeiro_semestre_2021 = separa_avaliacoes_por_semestre(aval_processadas, 2021, 1).groupby('sentimento')['sentimento'].count()\n",
    "\n",
    "    for table in [primeiro_semestre_2019, segundo_semestre_2019, primeiro_semestre_2020, segundo_semestre_2020, primeiro_semestre_2021]:\n",
    "        for i in range(-4,5):\n",
    "            if i not in table:\n",
    "                table[i]=0\n",
    "\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(nrows=1,ncols=5 ,figsize=(40, 8))\n",
    "    primeiro_semestre_2019_total = primeiro_semestre_2019.sum()\n",
    "    (primeiro_semestre_2019.sort_index()/primeiro_semestre_2019_total).plot.bar(ax=ax1, rot=0)\n",
    "    ax1.set(xlabel=\"Sentiment Score\", ylabel=\"Frequency\")\n",
    "    ax1.set_title(f\"Sentiment score distribution of {tipo_aval} reviews\\nin {cidade}\\nFirst semester of 2019 - Total of {primeiro_semestre_2019_total} reviews\")\n",
    "\n",
    "    segundo_semestre_2019_total = segundo_semestre_2019.sum()\n",
    "    (segundo_semestre_2019.sort_index()/segundo_semestre_2019_total).plot.bar(ax=ax2, rot=0)\n",
    "    ax2.set(xlabel=\"Sentiment Score\", ylabel=\"Frequency\")\n",
    "    ax2.set_title(f\"Sentiment score distribution of {tipo_aval} reviews\\nin {cidade}\\nSecond semester of 2019 - Total of {segundo_semestre_2019_total} reviews\")\n",
    "\n",
    "    primeiro_semestre_2020_total = primeiro_semestre_2020.sum()\n",
    "    (primeiro_semestre_2020.sort_index()/primeiro_semestre_2020_total).plot.bar(ax=ax3, rot=0)\n",
    "    ax3.set(xlabel=\"Sentiment Score\", ylabel=\"Frequency\")\n",
    "    ax3.set_title(f\"Sentiment score distribution of {tipo_aval} reviews\\nin {cidade}\\nFirst semester of 2020 - Total of {primeiro_semestre_2020_total} reviews\")\n",
    "\n",
    "    segundo_semestre_2020_total = segundo_semestre_2020.sum()\n",
    "    (segundo_semestre_2020.sort_index()/segundo_semestre_2020_total).plot.bar(ax=ax4, rot=0)\n",
    "    ax4.set(xlabel=\"Sentiment Score\", ylabel=\"Frequency\")\n",
    "    ax4.set_title(f\"Sentiment score distribution of {tipo_aval} reviews\\nin {cidade}\\nSecond semester of 2020 - Total of {segundo_semestre_2020_total} reviews\")\n",
    "\n",
    "    primeiro_semestre_2021_total = primeiro_semestre_2021.sum()\n",
    "    (primeiro_semestre_2021.sort_index()/primeiro_semestre_2021_total).plot.bar(ax=ax5, rot=0)\n",
    "    ax5.set(xlabel=\"Sentiment Score\", ylabel=\"Frequency\")\n",
    "    ax5.set_title(f\"Sentiment score distribution of {tipo_aval} reviews\\nin {cidade}\\nFirst semester of 2021 - Total of {primeiro_semestre_2021_total} reviews\")\n",
    "\n",
    "    for ax in (ax1, ax2, ax3, ax4, ax5):\n",
    "        for p in ax.patches:\n",
    "            width = p.get_width()\n",
    "            height = p.get_height()\n",
    "            x, y = p.get_xy() \n",
    "            ax.annotate(f'{height:.1%}', (x + width/2, y + height*1.02), ha='center', size='large')\n",
    "\n",
    "    fig.tight_layout(pad=5.0)\n",
    "    title = f\"{cidade.lower()} sentiment {tipo_aval}\".replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "def analise_sentimento_pandemia(cidade, aval_processadas, senti, tipo_aval):\n",
    "    aval_processadas['sentimento'] = aval_processadas.apply(lambda row: senti.getSentiment(row['processado'])[0], axis=1)\n",
    "\n",
    "    pre_pandemia = aval_processadas[(aval_processadas['data_avaliacao'] >= pd.Timestamp(2019, 4, 1)) & (aval_processadas['data_avaliacao'] < pd.Timestamp(2020, 4, 1))]\n",
    "    pos_pandemia = aval_processadas[aval_processadas['data_avaliacao'] >= pd.Timestamp(2020, 4, 1)]\n",
    "\n",
    "    sentimento_pre_pandemia = pre_pandemia.groupby(\"sentimento\")[\"sentimento\"].count()\n",
    "    sentimento_pos_pandemia = pos_pandemia.groupby(\"sentimento\")[\"sentimento\"].count()\n",
    "\n",
    "    total_pre_pandemia = sentimento_pre_pandemia.sum()\n",
    "    total_pos_pandemia = sentimento_pos_pandemia.sum()\n",
    "\n",
    "    for table in [sentimento_pre_pandemia, sentimento_pos_pandemia]:\n",
    "        for i in range(-4,5):\n",
    "            if i not in table:\n",
    "                table[i]=0\n",
    "\n",
    "    df1 = (sentimento_pre_pandemia.sort_index()/total_pre_pandemia)\n",
    "    df2 = (sentimento_pos_pandemia.sort_index()/total_pos_pandemia)\n",
    "    dataframe = pd.DataFrame({f\"Pre-Pandemic - {total_pre_pandemia} reviews\": df1, f\"Post-Pandemic - {total_pos_pandemia} reviews\": df2})\n",
    "    ax = dataframe.plot.bar(rot=0)\n",
    "    ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "    ax.set(xlabel=\"Sentiment Score\", ylabel=\"Frequency\")\n",
    "    ax.set_title(f\"Sentiment score distribution of {tipo_aval} reviews in {cidade}\\nPre (Apr 2019 to March 2020) and Post (Apr 2020 to March 2021) Pandemic\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    title = f\"{cidade.lower()} sentiment 2 {tipo_aval}\".replace(' ','_')\n",
    "    plt.savefig(os.path.join('graficos', cidade, title+'.png'))\n",
    "\n",
    "\n",
    "def analise_sentimento_por_semestre(cidade, avaliacoes):\n",
    "    senti = PySentiStr()\n",
    "    senti.setSentiStrengthPath(\"C:/SentStrength_Data/SentiStrengthCom.jar\")\n",
    "    senti.setSentiStrengthLanguageFolderPath(\"C:/SentStrength_Data\")\n",
    "\n",
    "    aval_processadas = pre_processa_aval(avaliacoes)\n",
    "    # analise_sentimento(cidade, aval_processadas['aval_hotel'], senti, \"hotel\")\n",
    "    # analise_sentimento(cidade, aval_processadas['aval_rest'], senti, \"restaurant\")\n",
    "    # analise_sentimento(cidade, aval_processadas['aval_atracoes'], senti, \"attraction\")\n",
    "    analise_sentimento_pandemia(cidade, aval_processadas['aval_hotel'], senti, \"hotel\")\n",
    "    analise_sentimento_pandemia(cidade, aval_processadas['aval_rest'], senti, \"restaurant\")\n",
    "    analise_sentimento_pandemia(cidade, aval_processadas['aval_atracoes'], senti, \"attraction\")\n",
    "\n",
    "def separa_avaliacoes_por_semestre(avaliacoes, ano, semestre):\n",
    "    comparacao = '<= 6' if semestre == 1 else '> 6'\n",
    "    aval_filtrada = avaliacoes.query(f'data_avaliacao.dt.year == {ano} and data_avaliacao.dt.month {comparacao}')\n",
    "\n",
    "    return aval_filtrada\n",
    "\n",
    "def csv_regressao(cidade):\n",
    "    dados_cidade = carrega_cidades(cidade)\n",
    "    estabelecimentos = dados_cidade['estabelecimentos']\n",
    "    avaliacoes = dados_cidade['avaliacoes']\n",
    "    avaliacoes_recentes = filtra_avaliacoes_antigas(avaliacoes)\n",
    "\n",
    "    rest = avaliacoes_recentes['aval_rest'].groupby(\"data_avaliacao\")['conteudo'].count().to_frame()\n",
    "    hotel = avaliacoes_recentes['aval_hotel'].groupby(\"data_avaliacao\")['conteudo'].count().to_frame()\n",
    "    atr = avaliacoes_recentes['aval_atracoes'].groupby(\"data_avaliacao\")['conteudo'].count().to_frame()\n",
    "    join1 = rest.join(hotel, rsuffix=\"2\", how=\"outer\")\n",
    "    result = join1.join(atr, rsuffix=\"3\", how=\"outer\")\n",
    "    result = result.rename(columns={\"conteudo\": \"aval_rest\", \"conteudo2\": \"aval_hotel\", \"conteudo3\": \"aval_atracoes\"})\n",
    "    result = result.fillna(0).astype(\"int32\")\n",
    "    result['cidade'] = cidade\n",
    "\n",
    "    return result\n",
    "\n",
    "def csv_regressao2(cidade):\n",
    "    dados_cidade = carrega_cidades(cidade)\n",
    "    estabelecimentos = dados_cidade['estabelecimentos']\n",
    "    avaliacoes = dados_cidade['avaliacoes']\n",
    "    avaliacoes_recentes = filtra_avaliacoes_antigas(avaliacoes)\n",
    "\n",
    "    aval_rest = avaliacoes_recentes['aval_rest']\n",
    "    rest = estabelecimentos['restaurantes']\n",
    "    result = aval_rest.merge(rest, left_on=\"estabelecimento_id\", right_on=\"restaurante_id\", suffixes=(\"_avaliacao\", \"_restaurante\"))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cidade = 'Ouro Preto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-2-011f97ee8c04>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_without_indef[coluna_data] = convert_to_datetime(df_without_indef, coluna_data)\n<ipython-input-2-011f97ee8c04>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_without_indef[coluna_data] = convert_to_datetime(df_without_indef, coluna_data)\n<ipython-input-2-011f97ee8c04>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_without_indef[coluna_data] = convert_to_datetime(df_without_indef, coluna_data)\n<ipython-input-2-011f97ee8c04>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_without_indef[coluna_data] = convert_to_datetime(df_without_indef, coluna_data)\n"
     ]
    }
   ],
   "source": [
    "dados_cidade = carrega_cidades(cidade)\n",
    "estabelecimentos = dados_cidade['estabelecimentos']\n",
    "avaliacoes = dados_cidade['avaliacoes']\n",
    "avaliacoes_recentes = filtra_avaliacoes_antigas(avaliacoes)\n",
    "avaliacoes_pandemia = filtra_avaliacoes_antigas(avaliacoes, ano=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analise_sentimento_por_semestre(cidade, avaliacoes_pandemia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#descreve_cidades(cidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordclouds(cidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_op = csv_regressao(\"Ouro Preto\")\n",
    "# csv_mar = csv_regressao(\"Mariana\")\n",
    "# result = pd.concat([csv_op, csv_mar])\n",
    "# result.shape\n",
    "# result.to_csv(\"regressao.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-2-011f97ee8c04>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_without_indef[coluna_data] = convert_to_datetime(df_without_indef, coluna_data)\n<ipython-input-2-011f97ee8c04>:9: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_without_indef[coluna_data] = convert_to_datetime(df_without_indef, coluna_data)\n"
     ]
    }
   ],
   "source": [
    "csv_op = csv_regressao2(\"Ouro Preto\")\n",
    "csv_mar = csv_regressao2(\"Mariana\")\n",
    "result = pd.concat([csv_op, csv_mar])\n",
    "result = result[['estabelecimento', 'estabelecimento_id', 'data_avaliacao', 'data_visita', 'origem', 'endereco', 'cidade', 'latitude', 'longitude']]\n",
    "result.to_csv(\"regressao_restaurante.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}